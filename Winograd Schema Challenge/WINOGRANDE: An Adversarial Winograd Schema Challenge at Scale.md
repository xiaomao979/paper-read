参考：https://blog.csdn.net/boywaiter/article/details/105590500

# 摘要
常识性推理的基准Winograd Schema Challenge（WSC）（Levesque，Davis和Morgenstern，2011年）是一组专家精心设计的273个代词消解问题，最初设计是为了使仅依赖选择偏好或单词关联的统计模型无法解决这些问题。但是，神经语言模型的最新进展在WSC的变体上已经达到了大约90％的准确性。这就提出了一个重要的问题，即这些模型是否真正获得了强大的常识能力，或者它们是否依赖数据集中的虚假偏差而导致对机器常识的真实能力的高估。
为了研究这个问题，我们引入WINOGRANDE，这是一个由44K个问题组成的大规模数据集，其灵感来自于原始的WSC设计，但已进行了调整以提高数据集的规模和难度。数据集构建的关键步骤包括（1）精心设计的众包流程，（2）使用新颖的AFLITE算法减少系统偏差，该算法将人类可检测的单词关联泛化为机器可检测的嵌入关联。最佳的WINOGRANDE方法达到59.4 – 79.1％，比人类表现的94.0％低约15-35％（绝对值），具体取决于所允许的训练数据量（分别是2％– 100％）。
此外，我们在五个相关的基准上建立了最新的最佳结果-WSC（90.1％），DPR（93.1％），COPA（90.6％），KnowRef（85.6％）和Winogender（97.1％）。这些结果具有双重含义：一方面，它们证明了WINOGRANDE在用作迁移学习资源时的有效性。另一方面，他们担心我们在所有这些基准测试中可能高估了机器常识的真实功能。我们强调在现有和将来的基准测试中减少算法偏差的重要性，以减轻这种高估。
