# 摘要
经过大量原始文本数据训练的上下文表示法已经对NLP任务（包括问题回答和阅读理解）进行了显着改进。已经有工作表明语法，语义和词义知识包含在此类表示中，这解释了它们为何有益于此类任务。但是，有关情境化表示中所包含的常识知识的研究工作相对较少，这对于人类对问题的回答和阅读理解至关重要。我们通过在七个具有挑战性的基准测试中测试了GPT，BERT，XLNet和RoBERTa的常识能力，发现语言建模及其变体是提升模型常识能力的有效目标，而双向上下文和更大的训练集则是加分项。我们还发现，当前的模型无法很好地完成任务，需要更多必要的推理步骤。最后，我们通过制作双重测试用例来测试模型的健壮性，这些用例相互关联，这样一个样本的正确预测应该导致另一个样本的正确预测。有趣的是，这些模型在这些测试用例上显示出混乱，这表明它们在表面而不是深层学习常识。我们发布了一个测试集，公开称为CAT，以供将来研究。
# 论文目的
用五种[GPT (Radford and Sutskever 2018), GPT2 (Radford et al.2019), BERT (Devlin et al. 2019), XLNet (Yang et al. 2019) and RoBERTa (Liu et al. 2019b)]最先进的模型来评估其中常识基准
