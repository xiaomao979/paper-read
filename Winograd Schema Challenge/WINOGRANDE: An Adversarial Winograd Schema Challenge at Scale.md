参考：https://blog.csdn.net/boywaiter/article/details/105590500

# 摘要
常识性推理的基准Winograd Schema Challenge（WSC）（Levesque，Davis和Morgenstern，2011年）是一组专家精心设计的273个代词消解问题，最初设计是为了使仅依赖选择偏好或单词关联的统计模型无法解决这些问题。但是，神经语言模型的最新进展在WSC的变体上已经达到了大约90％的准确性。这就提出了一个重要的问题，即这些模型是否真正获得了强大的常识能力，或者它们是否依赖数据集中的虚假偏差而导致对机器常识的真实能力的高估。  
为了研究这个问题，我们引入WINOGRANDE，这是一个由44K个问题组成的大规模数据集，其灵感来自于原始的WSC设计，但已进行了调整以提高数据集的规模和难度。数据集构建的关键步骤包括（1）精心设计的众包流程，（2）使用新颖的AFLITE算法减少系统偏差，该算法将人类可检测的单词关联泛化为机器可检测的嵌入关联。最佳的WINOGRANDE方法达到59.4 – 79.1％，比人类表现的94.0％低约15-35％（绝对值），具体取决于所允许的训练数据量（分别是2％– 100％）。  
此外，我们在五个相关的基准上建立了最新的最佳结果-WSC（90.1％），DPR（93.1％），COPA（90.6％），KnowRef（85.6％）和Winogender（97.1％）。这些结果具有双重含义：一方面，它们证明了WINOGRANDE在用作迁移学习资源时的有效性。另一方面，他们担心我们在所有这些基准测试中可能高估了机器常识的真实功能。我们强调在现有和将来的基准测试中减少算法偏差的重要性，以减轻这种高估。  

# Introduction
Winograd Schema Challenge（WSC）（Levesque，Davis和Morgenstern，2011年）作为图灵测试（Turing 1950年）的替代方案被提出，已被用作评估常识推理的基准。 WSC被设计为代词消解问题（请参见表1中的示例），该问题对人类而言是微不足道的，但对于仅依赖于统计模式却没有常识推理能力的机器而言，困难重重。但是，神经语言模型的最新进展已经报告了WSC数据集变体的准确率大约为90％。这提出了一个重要问题：  
- 神经语言模型是否已成功获得常识，或者我们是否高估了机器常识的真实能力？  
有关潜在高估的问题导致了另一个关键问题，即关于大规模神经语言模型可能正在利用潜在不需要的偏差的问题，本质上是正确解决了问题，但却是根据错误的理由。尽管WSC问题是专家精心设计的，但最近的研究表明，它们仍然容易出现偶然偏差。Trichelair等（2018）报告了单词关联（占13.5％的情况，请参见表1）以及其他类型的特定于数据集的偏差。尽管此类偏差和标注伪像在单个实例中并不明显，但由于问题的作者下意识地重复了类似的问题构造策略，它们已被引入数据集中。  
为了调查有关机器常识能力的真实估计的问题，我们引入了WINOGRANDE，这是一个新数据集，包含受WSC原始设计启发而产生的44k问题，但经过修改以提高问题的规模和难度。 WINOGRANDE构建的关键步骤包括（1）精心设计的众包流程，然后是（2）一种新颖的算法AFLITE，该算法将基于单词出现的人类可检测偏差泛化为基于嵌入出现的机器可检测偏差。我们方法的主要动机是，人类编写问题时难免会在不知不觉中引入不需要的偏差。  
虽然WINOGRANDE问题对于人类微不足道，准确性高达94％，但机器最佳结果（包括RoBERTa的结果）（Liu等人，2019年）要低得多，取决于训练数据的数量，介于59.4％-79.1％之间（从800到41k个实例），比人类水平的性能低15-35％（绝对值）。  
此外，我们还证明WINOGRANDE向其他现有WSC和相关基准提供了迁移学习，并在其中五个上实现了新的SOTA，包括原始WSC（Levesque，Davis和Morgenstern 2011）（90.1％），DPR（Rahman和Ng 2012）（93.1％），COPA（Roemmele，Bejan和Gordon 2011）（90.6％），KnowRef（Emami等人2019）（85.6％）和Winogender（Rudinger等人2018）（ 97.1％）。  
尽管SOTA在多个具有挑战性的基准上的改进令人振奋，但我们谨慎地注意到，这些积极的结果必须审慎视之。该结果还可能表明在现有数据集中普遍存在虚假效果的程度，这冒着高估常识性推理中机器智能真实能力的风险。更一般而言，人为设计的问题和任务（无论它们是由众包还是专家提供）在许多情况下都包含标注伪像，而算法上的偏差缩减（例如AFLITE）对于减轻此类特定于数据集的偏差至关重要。  

# 大规模众包WINOGRANDE
由于句对的结构性限制和语言知识的要求，WSC问题被认为很难通过众包进行手工制作（表1）。但是，我们提出了一种有效的方法来创建WSC问题的大规模数据集（WINOGRANDE），同时保持其原始属性，即对人类而言微不足道，而对于AI系统而言却很难。我们的方法包括精心设计的众包任务，然后是新颖的对抗过滤算法（第3节），该算法可以系统地消除数据中的偏差。
## 增强众包的创造力  
从头开始创建句对会给众包工人带来很大的认知负担，从而他们下意识地诉诸于撰写在词法和风格上重复的句对。为了鼓励创造力并减少他们的认知负担，我们采用了限制条件下的创造力（Stokes，2005年），这是一种心理观念，表明适当的约束条件可以帮助组织和推动创造力。在实践中，众包工人被要求将随机选择的主题作为提示性上下文（以下详述），同时要求他们遵循精选数据的结构的精确原则。
## 众包任务 
我们通过Amazon Mechanical Turk（AMT）上的众包收集WINOGRANDE问题。要求工人写出符合WSC问题要求的句对（如表1所示）（例如，避免单词关联，非零但很小的编辑距离）。为了避免重复相同的主题，工人被指示从随机分配的WikiHow文章中随机选择一个锚词，并确保两个句子都包含锚词。锚词不必一定是触发词，但是我们确保它不是诸如of，it，he，of之类的功能词。在我们的试点实验中，我们发现此限制极大地提高了工人的创造力和主题多样性。此外，还指示工人将句对长度保持在15到30个字之间，同时使句对之间的字词重叠率至少保持70％。根据最初的WSC问题，我们旨在在两个不同的领域收集句对（i）社会常识：一种情况，涉及两个具有相同性别，具有不同属性，情感，社会角色等的性别众包，以及（ii）身体常识：一种环境，涉及两个具有不同属性，用法，位置等物理对象的环境。 我们总共收集到77k个问题（即38k个句对）。
## 数据验证 
我们通过三个不同的众包工人来验证每个收集的问题。经过严格的过程，如果（1）三名工人中的大多数选择了正确的答案选项，（2）他们同意两个答案选项是明确的（一个选项显然比另一个选项更合理），则认为该问题有效（3）不能简单地通过给出目标代词周围局部上下文的单词关联来回答问题（例如，“因为它行进得如此之快。”（赛车/校车））。结果有68％（53k）的问题被视为有效，我们丢弃了无效的问题。  

尽管我们的众包过程解决了诸如单词关联之类的一些实例级别的偏差，但构造的数据集仍有可能具有特定于数据集的偏差-尤其是在扩大规模之后。为了应对这一挑战，我们提出了一种减少系统偏差的方法。

# 算法上的数据偏差缩减
最近的一些研究（Gururangan等人2018; Poliak等人2018; Tsuchiya 2018; Niven和Kao 2019; Geva，Goldberg和Berant 2019）报告了大规模数据集中存在标注伪像的情况。标注伪像是数据中的意外模式，会以不希望的方式泄漏有关目标标签的信息。最先进的神经模型在利用此类伪像来正确解决问题方面非常有效，但却是根据错误的理由。为了解决数据集偏差带来的持续挑战，我们提出了AFLITE-一种新颖的算法，该算法可以使用最先进的词语上下文表示来系统地减少偏差。

## 轻量级对抗过滤 
我们的方法基于Zellers等人提出的对抗过滤（AF）算法（2018），但进行了两项关键改进：（1）AFLITE的适用范围更广（不需要过多生成数据实例）；（2）轻量得多（不需要在AF的每次迭代都重新训练模型）。从语言模型过度生成机器文本以用于测试实例会带来分布偏差的风险，在这种情况下，判别器可以学会区分机器生成的实例和人工生成的实例。此外，AF依赖于每次迭代都训练模型，当与BERT之类的模型对抗时，这会花费极高的计算成本（Devlin等人，2018）。我们采用了实例的预计算神经网络嵌入作为其稠密表示，以代替人工识别的词汇特征。在这项工作中，我们使用数据集的一小部分对RoBERTa（Liu et al.2019）进行微调。具体来说，我们使用数据集（总共包含53k个实例）中的6k个实例（用于训练的5k和用于验证的1k）来微调RoBERTa。我们使用RoBERTa预计算其余实例（47k）的嵌入，作为AFLITE的输入。我们从最终数据集中丢弃了6k个实例。接下来，我们使用数据的随机子集上训练的线性分类器（逻辑回归）集成模型来确定RoBERTa中使用的表示是否强烈指示正确的答案选项。如果是这样，我们将丢弃相应的实例并进行迭代。  
算法1提供了AFLITE的实现。该算法将预先计算的嵌入X和标签y以及集成模型的大小n，集成模型中分类器的训练集大小m，过滤临界值（cutoff）的大小k和过滤阈值τ作为输入。在每个过滤阶段，我们在数据的不同随机分片上训练n个线性分类器，并在对应的验证集上收集它们的预测。对于每个实例，我们将正确预测与预测总数之比作为其得分。我们根据实例的得分对实例进行排名，并删除得分高于阈值τ的前k个实例。我们重复此过程，直到在过滤阶段删除少于k个实例或剩余少于m个实例为止。当将AFLITE应用于WINOGRANDE时，我们将m设置为10,000，n = 64，k = 500，τ= 0:75。
这种方法也让人联想到NLP最近在对抗性学习方面的工作（Chen and Cardie 2018; Belinkov et al.2019; Elazar and Goldberg 2018）。 Belinkov等（2019）提出了一种针对NLI的对抗移除技术，该技术鼓励模型学习没有仅假设偏差的表示。但是，当提出新的基准时，我们不能强制任何未来的模型有目的地避免学习数据中的虚假相关性。此外，尽管仅假设偏差是NLI中有见地的偏差，但我们不对WINOGRANDE的偏差的可能来源做出任何假设。取而代之的是，我们依靠最先进的（统计）方法来发现不良的数据集捷径，从而采取更为主动的减少偏差的形式。
## AFLITE的评估 
我们评估AFLITE对两个基准的影响：随机数据缩减和基于PMI的过滤。在随机数据缩减中，我们对数据集进行随机子采样以评估数据集大小的减小如何影响偏差。在基于PMI的过滤中，我们计算每个句对（t）的PMI之差（f）。  
从技术上讲，我们首先按照Gururangan等人提出的方法，为数据集中的每个单词预先计算了单词和标签y = 1之间的PMI（2018）。给定句子中每个标签的PMI值之和表示该句子的标签y = 1的可能性。我们仅保留其PMI值差异很小的句对，因为它对应于难以区分的句对。 


# 结论
我们介绍了WINOGRANDE，这是一个由44k 受WSC启发的问题的新集合，它比WSC数据集的现有变体要大得多。为了创建对伪数据偏差稳健的数据集，我们还介绍了AFLITE –一种新颖的轻量级对抗过滤算法，可用于系统性的偏差缩减。对于现有的最先进模型，所得的数据集具有更大的挑战性，而对人类而言仍然非常容易。此外，使用WINOGRANDE作为资源，我们演示了有效的迁移学习并在几个相关的基准上获得了最先进结果。
同时，我们还强调了在现有常识基准上高估现有技术方法性能的潜在风险；这些模型可能依靠虚假的统计模式（标注伪像）而以错误的原因正确地解决了问题。  
我们的工作为设计用于衡量AI进展的基准提供了新的视角。与过去数十年来社区构建静态基准数据集以在未来很多年内工作不同，我们现在需要AI算法来构成对AI来说足够困难的挑战，这需要动态数据集与不断发展的最先进技术一起发展。  
