# 论文目的
当前的语言模型主要有以下的问题
- insufficient coverage：常识无法捕获
- insufficient precision：准确率不高
- limited reasoning capabilities： 目前尚不清楚LMS是否能够执行涉及隐式知识的多个推理步骤    
为了增加高精度世界知识的覆盖范围，并通过使中间推理步骤明确来促进多跳推理， 作者研究预先训练的LMS作为外部KB的替代提供知识去完成限制满足问题。
 # 论文内容
 ## LM-only Baseline
 我们使用预先训练的语言模型LMS来评分不同文本片段的合理性，即利用语言模型，将文本问题答案拼接起来，然后看是否合理（给个评分）
 ## Baseline Model with External Knowledge
  每个实例由一个额外的说明列表组成。他们是从常识知识图谱当中抽取的，包含了解决实例的潜在相关知识。 例如，说明“实习的目的是帮助人们找到工作”可能有助于回答  提出了一个问题“布雷特和伊恩哪一个在毕业后找到了一份不那么快的工作？”。
## Self-talk Model
- Generating a clarification with LM：1）生成一个问题，条件取决于上下文（粉红色）和问题前缀（黄色）。 2）生成一个答案，该答案取决于上下文，生成的问题和相应的答案前缀。 说明是答案前缀和生成的文本（绿色）的串联


