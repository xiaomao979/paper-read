# 论文目的
ConceptNet依赖众包来获得重要的常识数据集合。 然而，它混淆了同义词（例如，温度意义上的“热”与时髦意义上的“热）；它还缺少细粒度的细节，例如特定种类的属性，对象之间的比较以及活动的详细知识。
在本文中，我们提出了一种基于一系列算法的系统，该系统可从大量文本中提取细粒度的消除歧义的常识。

# 论文方法
 为了实现这一具有挑战性的目标，我们将问题空间划分为三个研究方向。
 1. 对象的属性：获取诸如hasSize，hasShape等属性。我们开发了一种转导方法来编译语义组织的属性。
 2. 对象之间的关系：获取诸如bigThan，partOf，memberOf等关系。我们开发了一种基于线性规划的方法来编译比较关系，并且进一步开发了一种基于统计和逻辑推理的方法来编译部分整体关系。
 3. 它们之间的交互：通过基于表达的框架表示（包括时间和空间属性）来获取有关活动的知识，例如驾驶汽车，停放汽车等。 为此，我们的Knowlywood方法基于语义解析和概率图形模型来编译活动知识。
 
 ## 具体方法
 1. 以ConceptNet的子集为种子进行自举法抽取，为了减少噪音，我们使用 ranking function 来评判抽取结果
 2. 第一个算法 目的是 编译一组大而干净的细粒度常识属性，通过各种关系将名词感官与形容词感官联系起来。利用种子构架图，图的顶点是单词和词义，根据分类和分布相似性计算边的权重
 3. 第二个算法 提取和组织大规模的比较常识知识。利用“smaller than”, “more educated than” 等比较模式进行细化和抽取
 4，第三个算法 第三种算法侧重于提取和组织大规模的部分常识知识。我们再次依靠从文本中提取的原始断言，但是通过统计评分与逻辑推理相结合来提取这些断言，以说明断言的可传递性和继承（通过WordNet的上位词层次结构）。 为了估计可见性，我们验证图像中的断言（我们称为准视觉验证）。 准视觉验证利用了纯文本验证（由于报告偏差而导致的不准确）和仅视觉验证（由于对象检测器的不准确而导致的不准确）的最佳效果。
 5. 第四个算法 新任务提取和组织人类活动语义框架及其视觉内容。 我们从叙事文本中获得关于人类活动的知识，特别侧重于电影脚本，这些脚本是以场景为结构的，并提供场景集的描述 固定/位置、扬声器等。  此外，当脚本带有电影中具有代表性的图像或时间点时，可以将场景描述与电影的实际视觉内容对齐。 然而，主要的困难是电影脚本中所有这些丰富的内容都只是文本形式-仍然远离结构化的KB表示。 我们的方法考虑了联合语义角色标记和词义消歧来解析这些脚本，以生成活动框架的候选项。 然后，我们使用概率图形模型进行推理，该模型可以编码不同候选活动帧之间的联合依赖关系。  与以前的贡献不同，该方法超出了对断言参数的消歧；此外，还为这些参数分配角色。 最后的分类构造步骤将相似的活动框架分组在一起，并形成一个层次结构活动。 对于具有对齐电影数据的电影脚本，我们将相应的视频关键帧与我们的活动关联起来。 图3提供了结果活动框架的示例。
