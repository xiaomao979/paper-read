参考：https://blog.csdn.net/herosunly/article/details/90901995
# 摘要
NLP表示模型如BERT的预训练模型能够在大量的纯文本语料中捕获丰富的语义信息，并且通过微调改进NLP任务的效果。然而，已存在的预训练语言模型很少考虑将知识图谱的结构化信息融入其中，从而提高语言的理解。我们认为知识图谱中的信息实体能够增强语言表示。在这篇论文中，我们利用了大规模的语料信息和知识图谱，去训练一个增强的语言表示模型，它能够同时利用词汇、语义和知识信息。实验结果表明了ERNIE效果很好，在各项知识驱动的任务中都超过了BERT模型。源代码地址为： https://github.com/thunlp/ERNIE 。
